{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/facundo/.python/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "basepath='/media/data/datasets/sign/rwth-boston-104'\n",
    "basepath='/data/datasets/rwth-boston-104'\n",
    "basepath='/home/facundo/datasets/rwth-boston-104'\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "###################################\n",
    "# TensorFlow wizardry\n",
    "config = tf.ConfigProto()\n",
    " \n",
    "# Don't pre-allocate memory; allocate as-needed\n",
    "config.gpu_options.allow_growth = True\n",
    " \n",
    "# Create a session with the above options specified.\n",
    "K.tensorflow_backend.set_session(tf.Session(config=config))\n",
    "###################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets..\n",
      "Loaded 12422 frames. \n",
      "After filtering out of bounds positions, we have 11137 frames remaining. \n",
      "Loaded 3324 frames. \n",
      "After filtering out of bounds positions, we have 3320 frames remaining. \n",
      "Input shape (240, 316, 1)\n",
      "Classes 576\n"
     ]
    }
   ],
   "source": [
    "import boston104\n",
    "import target\n",
    "\n",
    "#body_parts=['head','right_hand','left_hand']\n",
    "\n",
    "localization_grid_shape=(12,16)\n",
    "localization_target=target.LocalizationTargetGrid(localization_grid_shape,body_parts)\n",
    "\n",
    "# max_distance=20\n",
    "# localization_target=target.LocalizationTargetRegression(max_distance,body_parts)\n",
    "\n",
    "print(\"Loading train dataset..\")\n",
    "video_positions_filepath=os.path.join(basepath,'handpositions/train.xml')\n",
    "batch_size=32\n",
    "train_iterator=boston104.Boston104LocalizationIterator(basepath,video_positions_filepath,localization_target,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "print(\"Loading test dataset..\")\n",
    "test_video_positions_filepath=os.path.join(basepath,'handpositions/test.xml')\n",
    "test_iterator=boston104.Boston104LocalizationIterator(basepath,test_video_positions_filepath,localization_target,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "input_shape=(train_iterator.h,train_iterator.w,1)\n",
    "classes = localization_target.dims()\n",
    "print(\"Input shape %s\" % str(input_shape))\n",
    "print(\"Classes %s\" % str(classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_iterator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-bf204a0b71fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m#iterator.image_position_to_grid_position(np.array([12,16]),np.array([240,316]),np.array([239,315]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;31m# print(batch_y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mbody_parts_coordinates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocalization_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions_to_body_parts_coordinates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_iterator' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "import matplotlib.patches as patches\n",
    "import utils\n",
    "\n",
    "def draw_coordinates(image_index,body_parts_coordinates_true,body_parts_coordinates_predicted=None,ax=plt.gca()):\n",
    "    #image_index=0\n",
    "    body_parts_colors_true={'head':'#ff0000','left_hand':'#00ff00','right_hand':'#0000ff'}     \n",
    "    body_parts_colors_predicted={'head':'#550000','left_hand':'#005500','right_hand':'#000055'}     \n",
    "    for bp in body_parts_coordinates_true.keys():\n",
    "            true_coordinates=body_parts_coordinates_true[bp]\n",
    "            draw_square(true_coordinates[image_index,:],color=body_parts_colors_true[bp],ax=ax)\n",
    "            if (body_parts_coordinates_predicted):\n",
    "                coordinates=body_parts_coordinates_predicted[bp]\n",
    "                draw_squarequare(coordinates[image_index,:],color=body_parts_colors_predicted[bp],ax=ax)\n",
    "    \n",
    "def draw_square(position,size=15,color='#eeefff',center=False,ax=plt.gca()):\n",
    "    \n",
    "    size_x,size_y=(size,size)\n",
    "    if center:\n",
    "        position_reversed=(position[1]-size_y/2,position[0]-size_x/2)\n",
    "    else:\n",
    "        position_reversed=(position[1],position[0])\n",
    "    rectangle=patches.Rectangle(position_reversed, size_x,size_y, fill=True,color=color)\n",
    "    ax.add_patch(rectangle)\n",
    "\n",
    "#iterator.image_position_to_grid_position(np.array([12,16]),np.array([240,316]),np.array([239,315]))\n",
    "    \n",
    "batch_x,batch_y=train_iterator.next()\n",
    "# print(batch_y)\n",
    "body_parts_coordinates=localization_target.predictions_to_body_parts_coordinates(batch_y,input_shape[0:2])\n",
    "\n",
    "true_coordinates=localization_target.predictions_to_body_parts_coordinates(batch_y,input_shape[0:2])\n",
    "\n",
    "image_index=0\n",
    "# print(true_coordinates[image_index,:])\n",
    "# print(body_parts_coordinates[body_parts[0]][image_index,:])\n",
    "image=np.copy(batch_x[image_index,:,:,0])\n",
    "# utils.draw_positions(image,{'head':true_coordinates[image_index,:].astype(int)})\n",
    "plt.imshow(image)\n",
    "draw_coordinates(image_index,true_coordinates)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 240, 316, 32)      320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 120, 158, 32)      9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 120, 158, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 120, 158, 32)      9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 120, 158, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 60, 79, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 60, 79, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 60, 79, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 60, 79, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 30, 40, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 30, 40, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 30, 40, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 30, 40, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 30, 40, 16)        4624      \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 30, 40, 8)         1160      \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 30, 40, 4)         292       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4800)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 150)               720150    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 576)               86976     \n",
      "=================================================================\n",
      "Total params: 869,778\n",
      "Trainable params: 869,394\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import models\n",
    "\n",
    "#model=models.resnext(input_shape,classes)\n",
    "model=models.simple_conv(input_shape,classes)\n",
    "#model=models.conv_mask(input_shape,classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 33s 325ms/step - loss: 3.5001 - metric: 0.1885\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 33s 329ms/step - loss: 3.0560 - metric: 0.3797\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 33s 334ms/step - loss: 2.9727 - metric: 0.4616\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 21s 208ms/step - loss: 2.9323 - metric: 0.5539\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 2.9156 - metric: 0.6591\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 2.8967 - metric: 0.7077\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 2.8944 - metric: 0.7273\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 2.8751 - metric: 0.7777\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 2.8758 - metric: 0.7810\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 2.8709 - metric: 0.7969\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "optimizer='rmsprop'\n",
    "#optimizer= optimizers.SGD(lr=0.005, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=localization_target.loss,#'categorical_crossentropy',\n",
    "              metrics=[localization_target.metric])\n",
    "\n",
    "history=model.fit_generator(train_iterator,steps_per_epoch=100, epochs=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.metrics_names)\n",
    "\n",
    "train_iterator.reset()\n",
    "test_iterator.reset()\n",
    "print(\"train loss, accuracy\", model.evaluate_generator(train_iterator,steps=iterator.n//iterator.batch_size+1))\n",
    "print(\"test loss, accuracy\", model.evaluate_generator(test_iterator,steps=test_iterator.n//test_iterator.batch_size+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb,yb=iterator.next()\n",
    "predictions = model.predict(xb, batch_size=batch_size)\n",
    "\n",
    "    \n",
    "\n",
    "body_parts_coordinates=localization_target.predictions_to_body_parts_coordinates(predictions,input_shape[0:2])\n",
    "body_parts_true_coordinates=localization_target.predictions_to_body_parts_coordinates(yb,input_shape[0:2])\n",
    "for bp in localization_grid_target.body_parts:\n",
    "    print(\"Body part: %s\" % bp)\n",
    "    true_coordinates=body_parts_true_coordinates[bp]\n",
    "    coordinates=body_parts_coordinates[bp]\n",
    "    print(coordinates[:18:2,:].T)\n",
    "# print(yb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            \n",
    "batches=2\n",
    "\n",
    "for batch in range(batches):\n",
    "    xb,yb=test_iterator.next()\n",
    "    predictions = model.predict(xb)\n",
    "    body_parts_coordinates_predicted=localization_target.predictions_to_body_parts_coordinates(predictions,input_shape[0:2])\n",
    "    body_parts_coordinates_true=localization_target.predictions_to_body_parts_coordinates(yb,input_shape[0:2])\n",
    "    \n",
    "    \n",
    "    batch_size=xb.shape[0]\n",
    "    for image_index in range(batch_size):\n",
    "#     image_index+=1 % batch_size\n",
    "#     image_index=image_index % batch_size\n",
    "    #print(xb.shape, \" ->\", )\n",
    "        plt.imshow(xb[image_index,:,:,0])\n",
    "        plt.title(\"%d / %d\" % (image_index,batch_size))\n",
    "        ax=plt.gca()\n",
    "        draw_coordinates(image_index,body_parts_coordinates_true,body_parts_coordinates_predicted,ax=ax)\n",
    "            \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "plt.tight_layout()\n",
    "i=0\n",
    "plt.figure()\n",
    "batches=test_iterator.n // batch_size\n",
    "while i<4:#batches:\n",
    "    xb,yb=test_iterator.next()\n",
    "    predictions = model.predict(xb)\n",
    "    body_parts_coordinates_predicted=localization_target.predictions_to_body_parts_coordinates(predictions,input_shape[0:2])\n",
    "    body_parts_coordinates_true=localization_target.predictions_to_body_parts_coordinates(yb,input_shape[0:2])\n",
    "    \n",
    "    batch_size=xb.shape[0]\n",
    "    f,axes = plt.subplots(8, 8,figsize=(20,10))\n",
    "    for image_index in range(batch_size):\n",
    "        subplot_i=image_index // 8\n",
    "        subplot_j= image_index % 8\n",
    "        ax=axes[subplot_i,subplot_j]\n",
    "        ax.imshow(xb[image_index,:,:,0])\n",
    "        draw_coordinates(image_index,body_parts_coordinates_true,body_parts_coordinates_predicted,ax=ax)\n",
    "        ax.axis('off')\n",
    "    plt.savefig(\"tmp/output/%06d.png\" % i, bbox_inches='tight',dpi=200)\n",
    "#     plt.show()\n",
    "\n",
    "    plt.close()\n",
    "    i=i+1\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
