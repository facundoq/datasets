{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/facundo/.python/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import keras\n",
    "\n",
    "import os\n",
    "import datasets\n",
    "import models\n",
    "dataset=\"cifar10\"\n",
    "(x_train, y_train), (x_test, y_test), input_shape,num_classes = datasets.get_data(dataset)\n",
    "\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv2D)               (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv11 (Conv2D)              (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv21 (Conv2D)              (None, 6, 6, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 6, 6, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv22 (Conv2D)              (None, 2, 2, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 64)                65600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 456,714\n",
      "Trainable params: 455,690\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = models.simple_conv(input_shape,num_classes,filters=32)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.RMSprop(lr=0.0015),\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv2D)               (None, 30, 30, 64)        1792      \n",
      "_________________________________________________________________\n",
      "conv11 (Conv2D)              (None, 14, 14, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv21 (Conv2D)              (None, 6, 6, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv22 (Conv2D)              (None, 2, 2, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,818,634\n",
      "Trainable params: 1,816,586\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "rotated_model = models.simple_conv(input_shape,num_classes,filters=64)\n",
    "rotated_model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.RMSprop(lr=0.0015),\n",
    "              metrics=['accuracy'])\n",
    "print(rotated_model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with unrotated dataset...\n",
      "Epoch 1/50\n",
      "782/781 [==============================] - 6s 8ms/step - loss: 1.4526 - acc: 0.4799 - val_loss: 1.2806 - val_acc: 0.5467\n",
      "Epoch 2/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 1.0538 - acc: 0.6267 - val_loss: 1.1753 - val_acc: 0.5876\n",
      "Epoch 3/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.8460 - acc: 0.7052 - val_loss: 0.9961 - val_acc: 0.6566\n",
      "Epoch 4/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.6872 - acc: 0.7609 - val_loss: 1.1276 - val_acc: 0.6237\n",
      "Epoch 5/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.5532 - acc: 0.8079 - val_loss: 0.9708 - val_acc: 0.6881\n",
      "Epoch 6/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.4398 - acc: 0.8483 - val_loss: 1.2569 - val_acc: 0.6337\n",
      "Epoch 7/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.3491 - acc: 0.8795 - val_loss: 1.1448 - val_acc: 0.6847\n",
      "Epoch 8/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.2788 - acc: 0.9018 - val_loss: 1.7465 - val_acc: 0.5749\n",
      "Epoch 9/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.2299 - acc: 0.9209 - val_loss: 1.3390 - val_acc: 0.6796\n",
      "Epoch 10/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.1978 - acc: 0.9320 - val_loss: 1.4012 - val_acc: 0.6676\n",
      "Epoch 11/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.1658 - acc: 0.9424 - val_loss: 1.3874 - val_acc: 0.6779\n",
      "Epoch 12/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.1494 - acc: 0.9480 - val_loss: 1.5557 - val_acc: 0.6767\n",
      "Epoch 13/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.1397 - acc: 0.9522 - val_loss: 1.7907 - val_acc: 0.6814\n",
      "Epoch 14/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.1212 - acc: 0.9588 - val_loss: 1.7609 - val_acc: 0.6673\n",
      "Epoch 15/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.1134 - acc: 0.9609 - val_loss: 1.5852 - val_acc: 0.6779\n",
      "Epoch 16/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.1069 - acc: 0.9629 - val_loss: 1.8728 - val_acc: 0.6778\n",
      "Epoch 17/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.0977 - acc: 0.9668 - val_loss: 1.6529 - val_acc: 0.6797\n",
      "Epoch 18/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.0948 - acc: 0.9685 - val_loss: 1.7182 - val_acc: 0.6843\n",
      "Epoch 19/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.0926 - acc: 0.9692 - val_loss: 1.9330 - val_acc: 0.6725\n",
      "Epoch 20/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.0847 - acc: 0.9707 - val_loss: 1.9383 - val_acc: 0.6845\n",
      "Epoch 21/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.0813 - acc: 0.9722 - val_loss: 2.0576 - val_acc: 0.6806\n",
      "Epoch 22/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.0759 - acc: 0.9746 - val_loss: 1.9409 - val_acc: 0.6854\n",
      "Epoch 23/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.0719 - acc: 0.9751 - val_loss: 1.7480 - val_acc: 0.6697\n",
      "Epoch 24/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.0699 - acc: 0.9758 - val_loss: 1.9734 - val_acc: 0.6797\n",
      "Epoch 25/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.0674 - acc: 0.9775 - val_loss: 2.1319 - val_acc: 0.6822\n",
      "Epoch 26/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.0636 - acc: 0.9784 - val_loss: 1.7722 - val_acc: 0.6669\n",
      "Epoch 27/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.0597 - acc: 0.9799 - val_loss: 2.0548 - val_acc: 0.6820\n",
      "Epoch 28/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.0619 - acc: 0.9797 - val_loss: 2.1771 - val_acc: 0.6666\n",
      "Epoch 29/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.0586 - acc: 0.9801 - val_loss: 2.2872 - val_acc: 0.6889\n",
      "Epoch 30/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.0571 - acc: 0.9807 - val_loss: 1.4651 - val_acc: 0.6773\n",
      "Epoch 31/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.0524 - acc: 0.9825 - val_loss: 2.3387 - val_acc: 0.6828\n",
      "Epoch 32/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.0568 - acc: 0.9813 - val_loss: 2.0852 - val_acc: 0.6688\n",
      "Epoch 33/50\n",
      "782/781 [==============================] - 6s 8ms/step - loss: 0.0497 - acc: 0.9830 - val_loss: 1.9329 - val_acc: 0.6774\n",
      "Epoch 34/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.0530 - acc: 0.9825 - val_loss: 1.8174 - val_acc: 0.6794\n",
      "Epoch 35/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.0470 - acc: 0.9844 - val_loss: 2.1989 - val_acc: 0.6933\n",
      "Epoch 36/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.0530 - acc: 0.9828 - val_loss: 2.8810 - val_acc: 0.6584\n",
      "Epoch 37/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.0481 - acc: 0.9845 - val_loss: 2.1037 - val_acc: 0.6829\n",
      "Epoch 38/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.0495 - acc: 0.9838 - val_loss: 2.6501 - val_acc: 0.6813\n",
      "Epoch 39/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.0468 - acc: 0.9851 - val_loss: 1.8445 - val_acc: 0.6818\n",
      "Epoch 40/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.0465 - acc: 0.9848 - val_loss: 1.6463 - val_acc: 0.6793\n",
      "Epoch 41/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.0442 - acc: 0.9856 - val_loss: 2.1071 - val_acc: 0.6822\n",
      "Epoch 42/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.0456 - acc: 0.9855 - val_loss: 1.9656 - val_acc: 0.6734\n",
      "Epoch 43/50\n",
      "782/781 [==============================] - 6s 8ms/step - loss: 0.0423 - acc: 0.9864 - val_loss: 2.2297 - val_acc: 0.6851\n",
      "Epoch 44/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.0423 - acc: 0.9858 - val_loss: 2.4532 - val_acc: 0.6850\n",
      "Epoch 45/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.0396 - acc: 0.9871 - val_loss: 1.6204 - val_acc: 0.6423\n",
      "Epoch 46/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.0400 - acc: 0.9866 - val_loss: 2.2844 - val_acc: 0.6786\n",
      "Epoch 47/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.0385 - acc: 0.9874 - val_loss: 2.6722 - val_acc: 0.6893\n",
      "Epoch 48/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.0372 - acc: 0.9872 - val_loss: 2.6317 - val_acc: 0.6795\n",
      "Epoch 49/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.0362 - acc: 0.9878 - val_loss: 2.4995 - val_acc: 0.6886\n",
      "Epoch 50/50\n",
      "782/781 [==============================] - 6s 7ms/step - loss: 0.0378 - acc: 0.9874 - val_loss: 2.6348 - val_acc: 0.6842\n",
      "Training rotated model with rotated dataset...\n",
      "Epoch 1/100\n",
      "782/781 [==============================] - 13s 17ms/step - loss: 1.8379 - acc: 0.3335 - val_loss: 1.9377 - val_acc: 0.3208\n",
      "Epoch 2/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 1.6069 - acc: 0.4193 - val_loss: 1.8616 - val_acc: 0.3554\n",
      "Epoch 3/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 1.4971 - acc: 0.4618 - val_loss: 2.0431 - val_acc: 0.3267\n",
      "Epoch 4/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 1.4138 - acc: 0.4946 - val_loss: 1.6728 - val_acc: 0.4101\n",
      "Epoch 5/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 1.3419 - acc: 0.5198 - val_loss: 3.2025 - val_acc: 0.2756\n",
      "Epoch 6/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 1.2839 - acc: 0.5447 - val_loss: 1.3554 - val_acc: 0.5157\n",
      "Epoch 7/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 1.2447 - acc: 0.5590 - val_loss: 1.2627 - val_acc: 0.5492\n",
      "Epoch 8/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 1.2100 - acc: 0.5719 - val_loss: 1.4167 - val_acc: 0.5086\n",
      "Epoch 9/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 1.1756 - acc: 0.5859 - val_loss: 2.3638 - val_acc: 0.3640\n",
      "Epoch 10/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 1.1569 - acc: 0.5930 - val_loss: 1.4338 - val_acc: 0.5064\n",
      "Epoch 11/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 1.1302 - acc: 0.6020 - val_loss: 1.8051 - val_acc: 0.4491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 1.1087 - acc: 0.6114 - val_loss: 1.3316 - val_acc: 0.5332\n",
      "Epoch 13/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 1.0866 - acc: 0.6185 - val_loss: 1.3099 - val_acc: 0.5544\n",
      "Epoch 14/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 1.0718 - acc: 0.6247 - val_loss: 1.1823 - val_acc: 0.5839\n",
      "Epoch 15/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 1.0481 - acc: 0.6324 - val_loss: 1.2354 - val_acc: 0.5798\n",
      "Epoch 16/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 1.0369 - acc: 0.6366 - val_loss: 1.1794 - val_acc: 0.5929\n",
      "Epoch 17/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 1.0192 - acc: 0.6422 - val_loss: 1.1694 - val_acc: 0.5914\n",
      "Epoch 18/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 1.0076 - acc: 0.6476 - val_loss: 1.3715 - val_acc: 0.5372\n",
      "Epoch 19/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.9898 - acc: 0.6541 - val_loss: 1.1370 - val_acc: 0.6074\n",
      "Epoch 20/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.9774 - acc: 0.6579 - val_loss: 1.4269 - val_acc: 0.5318\n",
      "Epoch 21/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.9653 - acc: 0.6633 - val_loss: 1.1537 - val_acc: 0.5956\n",
      "Epoch 22/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.9547 - acc: 0.6654 - val_loss: 1.2415 - val_acc: 0.5747\n",
      "Epoch 23/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.9406 - acc: 0.6696 - val_loss: 1.2758 - val_acc: 0.5673\n",
      "Epoch 24/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.9297 - acc: 0.6741 - val_loss: 1.2318 - val_acc: 0.5893\n",
      "Epoch 25/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.9191 - acc: 0.6806 - val_loss: 1.1067 - val_acc: 0.6168\n",
      "Epoch 26/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.9113 - acc: 0.6819 - val_loss: 1.1948 - val_acc: 0.6022\n",
      "Epoch 27/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.9019 - acc: 0.6864 - val_loss: 1.1185 - val_acc: 0.6093\n",
      "Epoch 28/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.8923 - acc: 0.6873 - val_loss: 1.1697 - val_acc: 0.6146\n",
      "Epoch 29/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.8793 - acc: 0.6925 - val_loss: 1.1625 - val_acc: 0.6173\n",
      "Epoch 30/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.8705 - acc: 0.6975 - val_loss: 1.1570 - val_acc: 0.6067\n",
      "Epoch 31/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.8694 - acc: 0.6977 - val_loss: 1.1376 - val_acc: 0.6210\n",
      "Epoch 32/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.8537 - acc: 0.7028 - val_loss: 1.1150 - val_acc: 0.6233\n",
      "Epoch 33/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.8477 - acc: 0.7056 - val_loss: 1.0858 - val_acc: 0.6296\n",
      "Epoch 34/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.8387 - acc: 0.7066 - val_loss: 1.2756 - val_acc: 0.5766\n",
      "Epoch 35/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.8360 - acc: 0.7094 - val_loss: 1.0545 - val_acc: 0.6384\n",
      "Epoch 36/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.8287 - acc: 0.7115 - val_loss: 1.0407 - val_acc: 0.6534\n",
      "Epoch 37/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.8203 - acc: 0.7139 - val_loss: 1.2198 - val_acc: 0.5998\n",
      "Epoch 38/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.8131 - acc: 0.7195 - val_loss: 1.2076 - val_acc: 0.6018\n",
      "Epoch 39/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.8085 - acc: 0.7189 - val_loss: 1.2102 - val_acc: 0.6079\n",
      "Epoch 40/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.8059 - acc: 0.7195 - val_loss: 1.0856 - val_acc: 0.6324\n",
      "Epoch 41/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.7948 - acc: 0.7231 - val_loss: 1.0939 - val_acc: 0.6282\n",
      "Epoch 42/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.7893 - acc: 0.7228 - val_loss: 1.0841 - val_acc: 0.6389\n",
      "Epoch 43/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.7899 - acc: 0.7269 - val_loss: 1.1352 - val_acc: 0.6208\n",
      "Epoch 44/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.7755 - acc: 0.7330 - val_loss: 1.1871 - val_acc: 0.5969\n",
      "Epoch 45/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.7700 - acc: 0.7339 - val_loss: 1.1086 - val_acc: 0.6289\n",
      "Epoch 46/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.7585 - acc: 0.7375 - val_loss: 1.0421 - val_acc: 0.6594\n",
      "Epoch 47/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.7573 - acc: 0.7369 - val_loss: 1.3365 - val_acc: 0.5920\n",
      "Epoch 48/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.7540 - acc: 0.7384 - val_loss: 1.0464 - val_acc: 0.6559\n",
      "Epoch 49/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.7418 - acc: 0.7406 - val_loss: 1.0908 - val_acc: 0.6436\n",
      "Epoch 50/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.7412 - acc: 0.7418 - val_loss: 1.1812 - val_acc: 0.6153\n",
      "Epoch 51/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.7392 - acc: 0.7429 - val_loss: 1.0776 - val_acc: 0.6450\n",
      "Epoch 52/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.7306 - acc: 0.7457 - val_loss: 1.1223 - val_acc: 0.6245\n",
      "Epoch 53/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.7271 - acc: 0.7475 - val_loss: 1.0635 - val_acc: 0.6402\n",
      "Epoch 54/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.7173 - acc: 0.7535 - val_loss: 1.2090 - val_acc: 0.6232\n",
      "Epoch 55/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.7159 - acc: 0.7531 - val_loss: 1.1140 - val_acc: 0.6491\n",
      "Epoch 56/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.7114 - acc: 0.7523 - val_loss: 1.1576 - val_acc: 0.6382\n",
      "Epoch 57/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.7019 - acc: 0.7537 - val_loss: 1.1486 - val_acc: 0.6299\n",
      "Epoch 58/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.7019 - acc: 0.7571 - val_loss: 1.1004 - val_acc: 0.6440\n",
      "Epoch 59/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.6941 - acc: 0.7577 - val_loss: 1.0171 - val_acc: 0.6645\n",
      "Epoch 60/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.6890 - acc: 0.7607 - val_loss: 1.0524 - val_acc: 0.6517\n",
      "Epoch 61/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.6927 - acc: 0.7594 - val_loss: 1.1696 - val_acc: 0.6175\n",
      "Epoch 62/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.6855 - acc: 0.7637 - val_loss: 1.1109 - val_acc: 0.6430\n",
      "Epoch 63/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.6823 - acc: 0.7625 - val_loss: 1.0317 - val_acc: 0.6749\n",
      "Epoch 64/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.6796 - acc: 0.7648 - val_loss: 1.1868 - val_acc: 0.6472\n",
      "Epoch 65/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.6685 - acc: 0.7678 - val_loss: 1.0726 - val_acc: 0.6591\n",
      "Epoch 66/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.6696 - acc: 0.7663 - val_loss: 1.1224 - val_acc: 0.6454\n",
      "Epoch 67/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.6627 - acc: 0.7696 - val_loss: 1.0919 - val_acc: 0.6543\n",
      "Epoch 68/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.6523 - acc: 0.7717 - val_loss: 1.0820 - val_acc: 0.6464\n",
      "Epoch 69/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.6535 - acc: 0.7741 - val_loss: 1.1029 - val_acc: 0.6622\n",
      "Epoch 70/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.6468 - acc: 0.7759 - val_loss: 1.0222 - val_acc: 0.6634\n",
      "Epoch 71/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.6472 - acc: 0.7747 - val_loss: 1.0918 - val_acc: 0.6629\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/781 [==============================] - 13s 16ms/step - loss: 0.6428 - acc: 0.7772 - val_loss: 1.1041 - val_acc: 0.6526\n",
      "Epoch 73/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.6409 - acc: 0.7778 - val_loss: 1.0806 - val_acc: 0.6613\n",
      "Epoch 74/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.6310 - acc: 0.7804 - val_loss: 1.1161 - val_acc: 0.6400\n",
      "Epoch 75/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.6336 - acc: 0.7801 - val_loss: 1.0717 - val_acc: 0.6551\n",
      "Epoch 76/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.6248 - acc: 0.7847 - val_loss: 1.0273 - val_acc: 0.6659\n",
      "Epoch 77/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.6246 - acc: 0.7838 - val_loss: 1.0902 - val_acc: 0.6618\n",
      "Epoch 78/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.6195 - acc: 0.7838 - val_loss: 1.0289 - val_acc: 0.6637\n",
      "Epoch 79/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.6176 - acc: 0.7852 - val_loss: 1.1085 - val_acc: 0.6578\n",
      "Epoch 80/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.6116 - acc: 0.7863 - val_loss: 1.0640 - val_acc: 0.6626\n",
      "Epoch 81/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.6045 - acc: 0.7891 - val_loss: 1.2588 - val_acc: 0.6256\n",
      "Epoch 82/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.6156 - acc: 0.7840 - val_loss: 1.0528 - val_acc: 0.6646\n",
      "Epoch 83/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.6064 - acc: 0.7887 - val_loss: 1.0318 - val_acc: 0.6760\n",
      "Epoch 84/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.5979 - acc: 0.7924 - val_loss: 1.0746 - val_acc: 0.6736\n",
      "Epoch 85/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.5923 - acc: 0.7957 - val_loss: 1.0739 - val_acc: 0.6656\n",
      "Epoch 86/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.6003 - acc: 0.7927 - val_loss: 1.0634 - val_acc: 0.6485\n",
      "Epoch 87/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.5878 - acc: 0.7968 - val_loss: 1.1008 - val_acc: 0.6593\n",
      "Epoch 88/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.5839 - acc: 0.7953 - val_loss: 1.2391 - val_acc: 0.6230\n",
      "Epoch 89/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.5829 - acc: 0.7988 - val_loss: 1.0521 - val_acc: 0.6720\n",
      "Epoch 90/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.5836 - acc: 0.7967 - val_loss: 1.1022 - val_acc: 0.6651\n",
      "Epoch 91/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.5770 - acc: 0.8005 - val_loss: 1.1329 - val_acc: 0.6626\n",
      "Epoch 92/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.5698 - acc: 0.8019 - val_loss: 1.0898 - val_acc: 0.6617\n",
      "Epoch 93/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.5756 - acc: 0.8002 - val_loss: 1.1879 - val_acc: 0.6425\n",
      "Epoch 94/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.5681 - acc: 0.8011 - val_loss: 1.0486 - val_acc: 0.6646\n",
      "Epoch 95/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.5642 - acc: 0.8035 - val_loss: 1.1720 - val_acc: 0.6612\n",
      "Epoch 96/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.5687 - acc: 0.8018 - val_loss: 1.1901 - val_acc: 0.6409\n",
      "Epoch 97/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.5620 - acc: 0.8035 - val_loss: 1.0791 - val_acc: 0.6721\n",
      "Epoch 98/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.5566 - acc: 0.8074 - val_loss: 1.1181 - val_acc: 0.6590\n",
      "Epoch 99/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.5544 - acc: 0.8068 - val_loss: 1.1119 - val_acc: 0.6636\n",
      "Epoch 100/100\n",
      "782/781 [==============================] - 13s 16ms/step - loss: 0.5520 - acc: 0.8088 - val_loss: 1.1589 - val_acc: 0.6619\n",
      "Testing both models on both datasets...\n",
      "rotated_model_test_dataset score: loss=1.134834, accuracy=0.675000\n",
      "model_test_dataset score: loss=2.634779, accuracy=0.684200\n",
      "rotated_model_rotated_test_dataset score: loss=1.131631, accuracy=0.666500\n",
      "model_rotated_test_dataset score: loss=6.982848, accuracy=0.315800\n"
     ]
    }
   ],
   "source": [
    "import experiment\n",
    "batch_size = 64\n",
    "epochs=50\n",
    "rotated_epochs=epochs*2\n",
    "scores=experiment.train_rotated(model,rotated_model,x_train,y_train,x_test,\n",
    "                          y_test,num_classes,input_shape,batch_size,epochs,rotated_epochs)\n",
    "\n",
    "\n",
    "for k,v in scores.items():\n",
    "    print('%s score: loss=%f, accuracy=%f' % (k,v[0],v[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
