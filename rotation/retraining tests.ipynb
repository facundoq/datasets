{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "residual_network() missing 1 required positional argument: 'width'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-259d441dfa10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m model.compile(loss=keras.losses.categorical_crossentropy,\n",
      "\u001b[0;32m~/dev/sld/rotation/models.py\u001b[0m in \u001b[0;36mget_model\u001b[0;34m(input_shape, num_classes, filters, frozen_layers)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfrozen_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresidual_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfrozen_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;31m#     model=simple_conv(input_shape,num_classes,frozen_layers)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: residual_network() missing 1 required positional argument: 'width'"
     ]
    }
   ],
   "source": [
    "\n",
    "import keras\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import datasets\n",
    "import models\n",
    "dataset=\"cifar10\"\n",
    "(x_train, y_train), (x_test, y_test), input_shape,num_classes = datasets.get_data(dataset)\n",
    "\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "batch_size = 32\n",
    "data_generator=ImageDataGenerator()\n",
    "train_dataset=data_generator.flow(x_train,y_train,shuffle=True,batch_size=batch_size)\n",
    "test_dataset=data_generator.flow(x_test,y_test,batch_size=batch_size)\n",
    "\n",
    "cardinality=32\n",
    "width=128\n",
    "model = models.residual_network(input_shape,num_classes,cardinality,width)\n",
    "\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.RMSprop(lr=0.0015),\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 15, 15, 128)  3584        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 15, 15, 32)   4128        conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 15, 15, 32)   4128        conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 15, 15, 32)   4128        conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 15, 15, 32)   4128        conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 15, 15, 32)   9248        conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 15, 15, 32)   9248        conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 15, 15, 32)   9248        conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 15, 15, 32)   9248        conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 15, 15, 128)  4224        conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 15, 15, 128)  4224        conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 15, 15, 128)  4224        conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 15, 15, 128)  4224        conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 15, 15, 128)  0           conv2d_127[0][0]                 \n",
      "                                                                 conv2d_130[0][0]                 \n",
      "                                                                 conv2d_133[0][0]                 \n",
      "                                                                 conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 15, 15, 128)  0           add_19[0][0]                     \n",
      "                                                                 conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 7, 7, 128)    147584      add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 7, 7, 32)     4128        conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 7, 7, 32)     4128        conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 7, 7, 32)     4128        conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 7, 7, 32)     4128        conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 7, 7, 32)     9248        conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 7, 7, 32)     9248        conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 7, 7, 32)     9248        conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 7, 7, 32)     9248        conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 7, 7, 128)    4224        conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 7, 7, 128)    4224        conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 7, 7, 128)    4224        conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 7, 7, 128)    4224        conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 7, 7, 128)    0           conv2d_140[0][0]                 \n",
      "                                                                 conv2d_143[0][0]                 \n",
      "                                                                 conv2d_146[0][0]                 \n",
      "                                                                 conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 7, 7, 128)    0           add_21[0][0]                     \n",
      "                                                                 conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 3, 3, 128)    147584      add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 3, 3, 64)     8256        conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 3, 3, 16)     1040        conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 3, 3, 16)     1040        conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 3, 3, 16)     1040        conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 3, 3, 16)     1040        conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 3, 3, 16)     2320        conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 3, 3, 16)     2320        conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 3, 3, 16)     2320        conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 3, 3, 16)     2320        conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 3, 3, 64)     1088        conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 3, 3, 64)     1088        conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 3, 3, 64)     1088        conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 3, 3, 64)     1088        conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 3, 3, 64)     0           conv2d_154[0][0]                 \n",
      "                                                                 conv2d_157[0][0]                 \n",
      "                                                                 conv2d_160[0][0]                 \n",
      "                                                                 conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 3, 3, 64)     0           add_23[0][0]                     \n",
      "                                                                 conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_59 (Flatten)            (None, 576)          0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "fc1 (Dense)                     (None, 128)          73856       flatten_59[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fc2 (Dense)                     (None, 10)           1290        fc1[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 540,746\n",
      "Trainable params: 540,746\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1563/1562 [==============================] - 28s 18ms/step - loss: 1.7060 - acc: 0.3800 - val_loss: 1.3798 - val_acc: 0.4976\n",
      "Epoch 2/15\n",
      "1563/1562 [==============================] - 27s 17ms/step - loss: 1.3052 - acc: 0.5335 - val_loss: 1.2490 - val_acc: 0.5428\n",
      "Epoch 3/15\n",
      "1563/1562 [==============================] - 27s 17ms/step - loss: 1.1516 - acc: 0.5925 - val_loss: 1.1233 - val_acc: 0.6056\n",
      "Epoch 4/15\n",
      "1563/1562 [==============================] - 27s 17ms/step - loss: 1.0832 - acc: 0.6188 - val_loss: 1.1141 - val_acc: 0.6213\n",
      "Epoch 5/15\n",
      "1563/1562 [==============================] - 27s 17ms/step - loss: 1.0723 - acc: 0.6283 - val_loss: 1.1984 - val_acc: 0.5871\n",
      "Epoch 6/15\n",
      "1563/1562 [==============================] - 27s 17ms/step - loss: 1.0647 - acc: 0.6302 - val_loss: 1.2451 - val_acc: 0.5662\n",
      "Epoch 7/15\n",
      "1563/1562 [==============================] - 27s 17ms/step - loss: 1.0689 - acc: 0.6285 - val_loss: 1.1028 - val_acc: 0.6265\n",
      "Epoch 8/15\n",
      "1563/1562 [==============================] - 27s 17ms/step - loss: 1.0691 - acc: 0.6320 - val_loss: 1.2093 - val_acc: 0.5841\n",
      "Epoch 9/15\n",
      "1563/1562 [==============================] - 27s 17ms/step - loss: 1.0889 - acc: 0.6279 - val_loss: 1.2336 - val_acc: 0.5907\n",
      "Epoch 10/15\n",
      "1563/1562 [==============================] - 27s 17ms/step - loss: 1.1112 - acc: 0.6240 - val_loss: 1.3387 - val_acc: 0.5212\n",
      "Epoch 11/15\n",
      "1563/1562 [==============================] - 27s 17ms/step - loss: 1.1306 - acc: 0.6167 - val_loss: 1.1826 - val_acc: 0.5996\n",
      "Epoch 12/15\n",
      "1563/1562 [==============================] - 27s 17ms/step - loss: 1.1499 - acc: 0.6106 - val_loss: 1.2459 - val_acc: 0.5738\n",
      "Epoch 13/15\n",
      "1563/1562 [==============================] - 27s 17ms/step - loss: 1.1562 - acc: 0.6119 - val_loss: 1.1973 - val_acc: 0.5786\n",
      "Epoch 14/15\n",
      "1563/1562 [==============================] - 27s 17ms/step - loss: 1.1552 - acc: 0.6132 - val_loss: 1.2823 - val_acc: 0.5642\n",
      "Epoch 15/15\n",
      "1563/1562 [==============================] - 27s 17ms/step - loss: 1.1492 - acc: 0.6127 - val_loss: 1.4957 - val_acc: 0.5140\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "epochs = 15\n",
    "\n",
    "weights_filename = 'rotation_test_model.hdf'\n",
    "model.save_weights(weights_filename, overwrite=True)\n",
    "if False and os.path.exists(weights_filename):\n",
    "    print('Loading existing weights')\n",
    "    model.load_weights(weights_filename)\n",
    "else:\n",
    "    model.fit_generator(train_dataset,\n",
    "          steps_per_epoch=len(x_train) / batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=test_dataset)\n",
    "    model.save_weights(weights_filename, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 1.9439 - acc: 0.2844 - val_loss: 1.7344 - val_acc: 0.3748\n",
      "Epoch 2/25\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.7067 - acc: 0.3809 - val_loss: 1.7730 - val_acc: 0.3601\n",
      "Epoch 3/25\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.6102 - acc: 0.4212 - val_loss: 1.5651 - val_acc: 0.4412\n",
      "Epoch 4/25\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.5449 - acc: 0.4463 - val_loss: 1.4855 - val_acc: 0.4711\n",
      "Epoch 5/25\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.4897 - acc: 0.4666 - val_loss: 1.4404 - val_acc: 0.4885\n",
      "Epoch 6/25\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.4489 - acc: 0.4792 - val_loss: 1.4235 - val_acc: 0.4931\n",
      "Epoch 7/25\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.4109 - acc: 0.4966 - val_loss: 1.3888 - val_acc: 0.5004\n",
      "Epoch 8/25\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.3705 - acc: 0.5128 - val_loss: 1.4737 - val_acc: 0.4865\n",
      "Epoch 9/25\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.3406 - acc: 0.5202 - val_loss: 1.3186 - val_acc: 0.5278\n",
      "Epoch 10/25\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.3082 - acc: 0.5338 - val_loss: 1.3109 - val_acc: 0.5320\n",
      "Epoch 11/25\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2798 - acc: 0.5416 - val_loss: 1.2808 - val_acc: 0.5437\n",
      "Epoch 12/25\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.2536 - acc: 0.5545 - val_loss: 1.2486 - val_acc: 0.5517\n",
      "Epoch 13/25\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.2210 - acc: 0.5651 - val_loss: 1.2504 - val_acc: 0.5558\n",
      "Epoch 14/25\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.1974 - acc: 0.5754 - val_loss: 1.2201 - val_acc: 0.5677\n",
      "Epoch 15/25\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.1713 - acc: 0.5831 - val_loss: 1.2251 - val_acc: 0.5608\n",
      "Epoch 16/25\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.1543 - acc: 0.5865 - val_loss: 1.1619 - val_acc: 0.5875\n",
      "Epoch 17/25\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.1312 - acc: 0.5976 - val_loss: 1.1762 - val_acc: 0.5813\n",
      "Epoch 18/25\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.1166 - acc: 0.6039 - val_loss: 1.1431 - val_acc: 0.5870\n",
      "Epoch 19/25\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.1005 - acc: 0.6092 - val_loss: 1.1723 - val_acc: 0.5775\n",
      "Epoch 20/25\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.0844 - acc: 0.6153 - val_loss: 1.1550 - val_acc: 0.5975\n",
      "Epoch 21/25\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.0697 - acc: 0.6184 - val_loss: 1.0901 - val_acc: 0.6141\n",
      "Epoch 22/25\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.0589 - acc: 0.6242 - val_loss: 1.0922 - val_acc: 0.6123\n",
      "Epoch 23/25\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.0454 - acc: 0.6302 - val_loss: 1.0872 - val_acc: 0.6184\n",
      "Epoch 24/25\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.0347 - acc: 0.6338 - val_loss: 1.1343 - val_acc: 0.6022\n",
      "Epoch 25/25\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.0247 - acc: 0.6356 - val_loss: 1.1897 - val_acc: 0.5867\n"
     ]
    }
   ],
   "source": [
    "rotated_epochs=25\n",
    "rotated_data_generator=ImageDataGenerator(rotation_range=180)\n",
    "rotated_train_dataset=rotated_data_generator.flow(x_train,y_train,shuffle=True,batch_size=batch_size)\n",
    "rotated_test_dataset=rotated_data_generator.flow(x_test,y_test,batch_size=batch_size)\n",
    "\n",
    "rotated_model = get_model(input_shape,num_classes,filters=64)\n",
    "\n",
    "rotated_model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "rotated_weights_filename = 'rotation_test_model_rotated.hdf'\n",
    "if False and os.path.exists(rotated_weights_filename):\n",
    "    print('Loading existing weights')\n",
    "    rotated_model.load_weights(rotated_weights_filename)\n",
    "else:\n",
    "    rotated_model.fit_generator(rotated_train_dataset,\n",
    "          steps_per_epoch=len(x_train) / batch_size,\n",
    "          epochs=rotated_epochs,\n",
    "          verbose=1,\n",
    "          validation_data=rotated_test_dataset)\n",
    "    rotated_model.save_weights(rotated_weights_filename, overwrite=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with frozen layers: ['conv1', 'conv2', 'fc1']\n",
      "Epoch 1/50\n",
      "1563/1562 [==============================] - 35s 22ms/step - loss: 1.7406 - acc: 0.3705 - val_loss: 1.6623 - val_acc: 0.3908\n",
      "Epoch 2/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.6225 - acc: 0.4071 - val_loss: 1.5696 - val_acc: 0.4300\n",
      "Epoch 3/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.5742 - acc: 0.4264 - val_loss: 1.5784 - val_acc: 0.4296\n",
      "Epoch 4/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.5427 - acc: 0.4367 - val_loss: 1.5277 - val_acc: 0.4449\n",
      "Epoch 5/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.5107 - acc: 0.4505 - val_loss: 1.5105 - val_acc: 0.4458\n",
      "Epoch 6/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.4886 - acc: 0.4566 - val_loss: 1.4845 - val_acc: 0.4568\n",
      "Epoch 7/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.4657 - acc: 0.4638 - val_loss: 1.4851 - val_acc: 0.4613\n",
      "Epoch 8/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.4534 - acc: 0.4721 - val_loss: 1.4455 - val_acc: 0.4730\n",
      "Epoch 9/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.4283 - acc: 0.4803 - val_loss: 1.4239 - val_acc: 0.4819\n",
      "Epoch 10/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.4173 - acc: 0.4859 - val_loss: 1.4231 - val_acc: 0.4865\n",
      "Epoch 11/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.4091 - acc: 0.4882 - val_loss: 1.3976 - val_acc: 0.4931\n",
      "Epoch 12/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.3922 - acc: 0.4946 - val_loss: 1.3977 - val_acc: 0.4980\n",
      "Epoch 13/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.3753 - acc: 0.5007 - val_loss: 1.4106 - val_acc: 0.4876\n",
      "Epoch 14/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.3723 - acc: 0.5052 - val_loss: 1.4382 - val_acc: 0.4887\n",
      "Epoch 15/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.3587 - acc: 0.5118 - val_loss: 1.3615 - val_acc: 0.5033\n",
      "Epoch 16/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.3502 - acc: 0.5102 - val_loss: 1.3418 - val_acc: 0.5127\n",
      "Epoch 17/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.3393 - acc: 0.5175 - val_loss: 1.3704 - val_acc: 0.5074\n",
      "Epoch 18/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.3321 - acc: 0.5173 - val_loss: 1.3249 - val_acc: 0.5160\n",
      "Epoch 19/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.3235 - acc: 0.5229 - val_loss: 1.3130 - val_acc: 0.5280\n",
      "Epoch 20/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.3145 - acc: 0.5256 - val_loss: 1.3123 - val_acc: 0.5306\n",
      "Epoch 21/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.3098 - acc: 0.5271 - val_loss: 1.3064 - val_acc: 0.5312\n",
      "Epoch 22/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2965 - acc: 0.5313 - val_loss: 1.3082 - val_acc: 0.5299\n",
      "Epoch 23/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2949 - acc: 0.5316 - val_loss: 1.3179 - val_acc: 0.5247\n",
      "Epoch 24/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2842 - acc: 0.5358 - val_loss: 1.2895 - val_acc: 0.5405\n",
      "Epoch 25/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2788 - acc: 0.5410 - val_loss: 1.2903 - val_acc: 0.5354\n",
      "Epoch 26/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2765 - acc: 0.5402 - val_loss: 1.2663 - val_acc: 0.5421\n",
      "Epoch 27/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2754 - acc: 0.5436 - val_loss: 1.2873 - val_acc: 0.5385\n",
      "Epoch 28/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2614 - acc: 0.5443 - val_loss: 1.2736 - val_acc: 0.5472\n",
      "Epoch 29/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2578 - acc: 0.5511 - val_loss: 1.2726 - val_acc: 0.5405\n",
      "Epoch 30/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.2505 - acc: 0.5486 - val_loss: 1.2744 - val_acc: 0.5387\n",
      "Epoch 31/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2506 - acc: 0.5500 - val_loss: 1.2702 - val_acc: 0.5417\n",
      "Epoch 32/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2374 - acc: 0.5530 - val_loss: 1.2448 - val_acc: 0.5515\n",
      "Epoch 33/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2361 - acc: 0.5547 - val_loss: 1.2412 - val_acc: 0.5563\n",
      "Epoch 34/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2378 - acc: 0.5524 - val_loss: 1.2797 - val_acc: 0.5512\n",
      "Epoch 35/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2312 - acc: 0.5568 - val_loss: 1.2626 - val_acc: 0.5471\n",
      "Epoch 36/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2202 - acc: 0.5635 - val_loss: 1.2526 - val_acc: 0.5493\n",
      "Epoch 37/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2166 - acc: 0.5635 - val_loss: 1.2613 - val_acc: 0.5556\n",
      "Epoch 38/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2170 - acc: 0.5643 - val_loss: 1.2322 - val_acc: 0.5635\n",
      "Epoch 39/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2043 - acc: 0.5670 - val_loss: 1.2237 - val_acc: 0.5659\n",
      "Epoch 40/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2050 - acc: 0.5668 - val_loss: 1.2431 - val_acc: 0.5551\n",
      "Epoch 41/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2034 - acc: 0.5683 - val_loss: 1.2153 - val_acc: 0.5678\n",
      "Epoch 42/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.1980 - acc: 0.5730 - val_loss: 1.2588 - val_acc: 0.5547\n",
      "Epoch 43/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.1952 - acc: 0.5721 - val_loss: 1.2062 - val_acc: 0.5647\n",
      "Epoch 44/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.1892 - acc: 0.5745 - val_loss: 1.2258 - val_acc: 0.5653\n",
      "Epoch 45/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.1878 - acc: 0.5747 - val_loss: 1.2009 - val_acc: 0.5745\n",
      "Epoch 46/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.1845 - acc: 0.5781 - val_loss: 1.2114 - val_acc: 0.5687\n",
      "Epoch 47/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.1806 - acc: 0.5775 - val_loss: 1.2053 - val_acc: 0.5703\n",
      "Epoch 48/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.1830 - acc: 0.5770 - val_loss: 1.1923 - val_acc: 0.5792\n",
      "Epoch 49/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.1730 - acc: 0.5806 - val_loss: 1.1994 - val_acc: 0.5722\n",
      "Epoch 50/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.1730 - acc: 0.5800 - val_loss: 1.2203 - val_acc: 0.5689\n",
      "Training model with frozen layers: ['conv1', 'conv2', 'fc2']\n",
      "Epoch 1/50\n",
      "1563/1562 [==============================] - 35s 22ms/step - loss: 1.7415 - acc: 0.3671 - val_loss: 1.6829 - val_acc: 0.3846\n",
      "Epoch 2/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.6481 - acc: 0.4029 - val_loss: 1.6337 - val_acc: 0.4066\n",
      "Epoch 3/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.6043 - acc: 0.4154 - val_loss: 1.5883 - val_acc: 0.4162\n",
      "Epoch 4/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.5660 - acc: 0.4312 - val_loss: 1.5801 - val_acc: 0.4254\n",
      "Epoch 5/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.5454 - acc: 0.4377 - val_loss: 1.5178 - val_acc: 0.4548\n",
      "Epoch 6/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.5132 - acc: 0.4519 - val_loss: 1.5363 - val_acc: 0.4518\n",
      "Epoch 7/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.5032 - acc: 0.4569 - val_loss: 1.5325 - val_acc: 0.4438\n",
      "Epoch 8/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.4795 - acc: 0.4654 - val_loss: 1.4634 - val_acc: 0.4671\n",
      "Epoch 9/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.4680 - acc: 0.4698 - val_loss: 1.4868 - val_acc: 0.4678\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.4532 - acc: 0.4749 - val_loss: 1.4430 - val_acc: 0.4705\n",
      "Epoch 11/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.4458 - acc: 0.4781 - val_loss: 1.4480 - val_acc: 0.4836\n",
      "Epoch 12/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.4297 - acc: 0.4845 - val_loss: 1.4496 - val_acc: 0.4779\n",
      "Epoch 13/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.4186 - acc: 0.4894 - val_loss: 1.4441 - val_acc: 0.4783\n",
      "Epoch 14/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.4122 - acc: 0.4929 - val_loss: 1.4155 - val_acc: 0.4801\n",
      "Epoch 15/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.4051 - acc: 0.4964 - val_loss: 1.4056 - val_acc: 0.5001\n",
      "Epoch 16/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.3970 - acc: 0.4963 - val_loss: 1.3863 - val_acc: 0.5059\n",
      "Epoch 17/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.3842 - acc: 0.5017 - val_loss: 1.3724 - val_acc: 0.5048\n",
      "Epoch 18/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.3830 - acc: 0.5021 - val_loss: 1.3573 - val_acc: 0.5142\n",
      "Epoch 19/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.3736 - acc: 0.5073 - val_loss: 1.3617 - val_acc: 0.5173\n",
      "Epoch 20/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.3649 - acc: 0.5086 - val_loss: 1.4039 - val_acc: 0.4987\n",
      "Epoch 21/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.3630 - acc: 0.5108 - val_loss: 1.3333 - val_acc: 0.5251\n",
      "Epoch 22/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.3506 - acc: 0.5174 - val_loss: 1.4348 - val_acc: 0.4887\n",
      "Epoch 23/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.3456 - acc: 0.5161 - val_loss: 1.4412 - val_acc: 0.4979\n",
      "Epoch 24/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.3446 - acc: 0.5189 - val_loss: 1.3820 - val_acc: 0.5137\n",
      "Epoch 25/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.3373 - acc: 0.5228 - val_loss: 1.3393 - val_acc: 0.5250\n",
      "Epoch 26/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.3356 - acc: 0.5228 - val_loss: 1.3566 - val_acc: 0.5158\n",
      "Epoch 27/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.3298 - acc: 0.5224 - val_loss: 1.3195 - val_acc: 0.5241\n",
      "Epoch 28/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.3220 - acc: 0.5287 - val_loss: 1.3577 - val_acc: 0.5145\n",
      "Epoch 29/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.3271 - acc: 0.5264 - val_loss: 1.3493 - val_acc: 0.5272\n",
      "Epoch 30/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.3159 - acc: 0.5279 - val_loss: 1.3338 - val_acc: 0.5197\n",
      "Epoch 31/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.3118 - acc: 0.5299 - val_loss: 1.3049 - val_acc: 0.5310\n",
      "Epoch 32/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.3088 - acc: 0.5336 - val_loss: 1.3995 - val_acc: 0.5096\n",
      "Epoch 33/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.3058 - acc: 0.5360 - val_loss: 1.3236 - val_acc: 0.5374\n",
      "Epoch 34/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.3023 - acc: 0.5350 - val_loss: 1.4254 - val_acc: 0.5087\n",
      "Epoch 35/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.2992 - acc: 0.5387 - val_loss: 1.3261 - val_acc: 0.5342\n",
      "Epoch 36/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2917 - acc: 0.5391 - val_loss: 1.3071 - val_acc: 0.5391\n",
      "Epoch 37/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2915 - acc: 0.5405 - val_loss: 1.2976 - val_acc: 0.5379\n",
      "Epoch 38/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2910 - acc: 0.5398 - val_loss: 1.3081 - val_acc: 0.5373\n",
      "Epoch 39/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2807 - acc: 0.5414 - val_loss: 1.3618 - val_acc: 0.5231\n",
      "Epoch 40/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2776 - acc: 0.5426 - val_loss: 1.3193 - val_acc: 0.5255\n",
      "Epoch 41/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.2795 - acc: 0.5460 - val_loss: 1.2981 - val_acc: 0.5403\n",
      "Epoch 42/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.2722 - acc: 0.5441 - val_loss: 1.3343 - val_acc: 0.5206\n",
      "Epoch 43/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2732 - acc: 0.5461 - val_loss: 1.2945 - val_acc: 0.5450\n",
      "Epoch 44/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.2753 - acc: 0.5452 - val_loss: 1.3010 - val_acc: 0.5369\n",
      "Epoch 45/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.2714 - acc: 0.5479 - val_loss: 1.2640 - val_acc: 0.5524\n",
      "Epoch 46/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2685 - acc: 0.5494 - val_loss: 1.2813 - val_acc: 0.5498\n",
      "Epoch 47/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2685 - acc: 0.5475 - val_loss: 1.3400 - val_acc: 0.5375\n",
      "Epoch 48/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2628 - acc: 0.5511 - val_loss: 1.3604 - val_acc: 0.5357\n",
      "Epoch 49/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2622 - acc: 0.5492 - val_loss: 1.2849 - val_acc: 0.5401\n",
      "Epoch 50/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.2668 - acc: 0.5481 - val_loss: 1.2523 - val_acc: 0.5521\n",
      "Training model with frozen layers: ['conv1', 'conv2']\n",
      "Epoch 1/50\n",
      "1563/1562 [==============================] - 36s 23ms/step - loss: 1.7231 - acc: 0.3727 - val_loss: 1.6707 - val_acc: 0.3890\n",
      "Epoch 2/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.6161 - acc: 0.4114 - val_loss: 1.6095 - val_acc: 0.4047\n",
      "Epoch 3/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.5777 - acc: 0.4260 - val_loss: 1.5425 - val_acc: 0.4365\n",
      "Epoch 4/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.5403 - acc: 0.4377 - val_loss: 1.5565 - val_acc: 0.4290\n",
      "Epoch 5/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.5160 - acc: 0.4496 - val_loss: 1.4879 - val_acc: 0.4543\n",
      "Epoch 6/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.4865 - acc: 0.4588 - val_loss: 1.4961 - val_acc: 0.4590\n",
      "Epoch 7/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.4640 - acc: 0.4678 - val_loss: 1.4649 - val_acc: 0.4763\n",
      "Epoch 8/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.4533 - acc: 0.4718 - val_loss: 1.4782 - val_acc: 0.4668\n",
      "Epoch 9/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.4384 - acc: 0.4766 - val_loss: 1.4369 - val_acc: 0.4833\n",
      "Epoch 10/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.4233 - acc: 0.4868 - val_loss: 1.4192 - val_acc: 0.4832\n",
      "Epoch 11/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.4140 - acc: 0.4854 - val_loss: 1.3964 - val_acc: 0.4966\n",
      "Epoch 12/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.4006 - acc: 0.4923 - val_loss: 1.3770 - val_acc: 0.5078\n",
      "Epoch 13/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.3846 - acc: 0.4993 - val_loss: 1.3718 - val_acc: 0.5015\n",
      "Epoch 14/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.3755 - acc: 0.5020 - val_loss: 1.4289 - val_acc: 0.4916\n",
      "Epoch 15/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.3659 - acc: 0.5082 - val_loss: 1.3636 - val_acc: 0.5084\n",
      "Epoch 16/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.3591 - acc: 0.5087 - val_loss: 1.3827 - val_acc: 0.5015\n",
      "Epoch 17/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.3483 - acc: 0.5138 - val_loss: 1.3528 - val_acc: 0.5055\n",
      "Epoch 18/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.3432 - acc: 0.5157 - val_loss: 1.3411 - val_acc: 0.5172\n",
      "Epoch 19/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.3385 - acc: 0.5160 - val_loss: 1.3502 - val_acc: 0.5141\n",
      "Epoch 20/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.3288 - acc: 0.5205 - val_loss: 1.3491 - val_acc: 0.5148\n",
      "Epoch 21/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.3276 - acc: 0.5191 - val_loss: 1.3580 - val_acc: 0.5061\n",
      "Epoch 22/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.3190 - acc: 0.5255 - val_loss: 1.3363 - val_acc: 0.5171\n",
      "Epoch 23/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.3166 - acc: 0.5270 - val_loss: 1.2974 - val_acc: 0.5324\n",
      "Epoch 24/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.3064 - acc: 0.5297 - val_loss: 1.3023 - val_acc: 0.5323\n",
      "Epoch 25/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.3038 - acc: 0.5322 - val_loss: 1.3062 - val_acc: 0.5312\n",
      "Epoch 26/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.2971 - acc: 0.5320 - val_loss: 1.2947 - val_acc: 0.5299\n",
      "Epoch 27/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.2953 - acc: 0.5338 - val_loss: 1.2776 - val_acc: 0.5413\n",
      "Epoch 28/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.2864 - acc: 0.5368 - val_loss: 1.3241 - val_acc: 0.5277\n",
      "Epoch 29/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.2908 - acc: 0.5364 - val_loss: 1.4079 - val_acc: 0.4927\n",
      "Epoch 30/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.2763 - acc: 0.5424 - val_loss: 1.2632 - val_acc: 0.5492\n",
      "Epoch 31/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.2730 - acc: 0.5422 - val_loss: 1.3138 - val_acc: 0.5259\n",
      "Epoch 32/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.2651 - acc: 0.5468 - val_loss: 1.2880 - val_acc: 0.5375\n",
      "Epoch 33/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.2673 - acc: 0.5457 - val_loss: 1.2691 - val_acc: 0.5427\n",
      "Epoch 34/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.2629 - acc: 0.5447 - val_loss: 1.2737 - val_acc: 0.5489\n",
      "Epoch 35/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.2559 - acc: 0.5529 - val_loss: 1.2586 - val_acc: 0.5500\n",
      "Epoch 36/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.2516 - acc: 0.5509 - val_loss: 1.2522 - val_acc: 0.5552\n",
      "Epoch 37/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.2495 - acc: 0.5519 - val_loss: 1.3068 - val_acc: 0.5314\n",
      "Epoch 38/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.2486 - acc: 0.5542 - val_loss: 1.2637 - val_acc: 0.5517\n",
      "Epoch 39/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.2475 - acc: 0.5533 - val_loss: 1.2451 - val_acc: 0.5495\n",
      "Epoch 40/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.2413 - acc: 0.5560 - val_loss: 1.2720 - val_acc: 0.5471\n",
      "Epoch 41/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.2344 - acc: 0.5585 - val_loss: 1.2637 - val_acc: 0.5543\n",
      "Epoch 42/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.2323 - acc: 0.5593 - val_loss: 1.2090 - val_acc: 0.5666\n",
      "Epoch 43/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.2295 - acc: 0.5599 - val_loss: 1.2343 - val_acc: 0.5626\n",
      "Epoch 44/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.2294 - acc: 0.5608 - val_loss: 1.2368 - val_acc: 0.5578\n",
      "Epoch 45/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.2225 - acc: 0.5626 - val_loss: 1.2454 - val_acc: 0.5549\n",
      "Epoch 46/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.2183 - acc: 0.5645 - val_loss: 1.2941 - val_acc: 0.5357\n",
      "Epoch 47/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.2122 - acc: 0.5674 - val_loss: 1.2170 - val_acc: 0.5606\n",
      "Epoch 48/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.2130 - acc: 0.5644 - val_loss: 1.2338 - val_acc: 0.5638\n",
      "Epoch 49/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.2138 - acc: 0.5679 - val_loss: 1.2219 - val_acc: 0.5633\n",
      "Epoch 50/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.2074 - acc: 0.5682 - val_loss: 1.2174 - val_acc: 0.5644\n",
      "Training model with frozen layers: ['fc1', 'fc2']\n",
      "Epoch 1/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 1.7516 - acc: 0.3662 - val_loss: 1.6678 - val_acc: 0.3925\n",
      "Epoch 2/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.6501 - acc: 0.3977 - val_loss: 1.6458 - val_acc: 0.3909\n",
      "Epoch 3/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.6023 - acc: 0.4202 - val_loss: 1.6103 - val_acc: 0.4149\n",
      "Epoch 4/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.5766 - acc: 0.4265 - val_loss: 1.5734 - val_acc: 0.4251\n",
      "Epoch 5/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.5533 - acc: 0.4363 - val_loss: 1.5490 - val_acc: 0.4327\n",
      "Epoch 6/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.5250 - acc: 0.4447 - val_loss: 1.5549 - val_acc: 0.4393\n",
      "Epoch 7/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.5067 - acc: 0.4524 - val_loss: 1.5093 - val_acc: 0.4603\n",
      "Epoch 8/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.4936 - acc: 0.4598 - val_loss: 1.4749 - val_acc: 0.4699\n",
      "Epoch 9/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.4721 - acc: 0.4679 - val_loss: 1.4535 - val_acc: 0.4809\n",
      "Epoch 10/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.4629 - acc: 0.4698 - val_loss: 1.4465 - val_acc: 0.4785\n",
      "Epoch 11/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.4512 - acc: 0.4739 - val_loss: 1.4557 - val_acc: 0.4764\n",
      "Epoch 12/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.4351 - acc: 0.4785 - val_loss: 1.4505 - val_acc: 0.4801\n",
      "Epoch 13/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.4190 - acc: 0.4858 - val_loss: 1.4426 - val_acc: 0.4855\n",
      "Epoch 14/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.4135 - acc: 0.4867 - val_loss: 1.4141 - val_acc: 0.4894\n",
      "Epoch 15/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.4008 - acc: 0.4969 - val_loss: 1.4190 - val_acc: 0.4903\n",
      "Epoch 16/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.3926 - acc: 0.4990 - val_loss: 1.4259 - val_acc: 0.4831\n",
      "Epoch 17/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.3814 - acc: 0.5033 - val_loss: 1.3782 - val_acc: 0.5060\n",
      "Epoch 18/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.3745 - acc: 0.5065 - val_loss: 1.3778 - val_acc: 0.5067\n",
      "Epoch 19/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.3699 - acc: 0.5050 - val_loss: 1.3911 - val_acc: 0.5032\n",
      "Epoch 20/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.3568 - acc: 0.5125 - val_loss: 1.3565 - val_acc: 0.5178\n",
      "Epoch 21/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.3514 - acc: 0.5157 - val_loss: 1.3542 - val_acc: 0.5139\n",
      "Epoch 22/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.3495 - acc: 0.5154 - val_loss: 1.3466 - val_acc: 0.5231\n",
      "Epoch 23/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.3409 - acc: 0.5175 - val_loss: 1.3678 - val_acc: 0.5139\n",
      "Epoch 24/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.3322 - acc: 0.5215 - val_loss: 1.3500 - val_acc: 0.5068\n",
      "Epoch 25/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.3265 - acc: 0.5238 - val_loss: 1.3258 - val_acc: 0.5243\n",
      "Epoch 26/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.3251 - acc: 0.5259 - val_loss: 1.3514 - val_acc: 0.5155\n",
      "Epoch 27/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.3179 - acc: 0.5280 - val_loss: 1.3207 - val_acc: 0.5267\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.3139 - acc: 0.5302 - val_loss: 1.3373 - val_acc: 0.5234\n",
      "Epoch 29/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.3044 - acc: 0.5339 - val_loss: 1.3272 - val_acc: 0.5272\n",
      "Epoch 30/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.3015 - acc: 0.5339 - val_loss: 1.3027 - val_acc: 0.5351\n",
      "Epoch 31/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2983 - acc: 0.5364 - val_loss: 1.3028 - val_acc: 0.5358\n",
      "Epoch 32/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2928 - acc: 0.5375 - val_loss: 1.3076 - val_acc: 0.5308\n",
      "Epoch 33/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2869 - acc: 0.5402 - val_loss: 1.3255 - val_acc: 0.5353\n",
      "Epoch 34/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2814 - acc: 0.5423 - val_loss: 1.3067 - val_acc: 0.5423\n",
      "Epoch 35/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.2837 - acc: 0.5421 - val_loss: 1.3142 - val_acc: 0.5316\n",
      "Epoch 36/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2697 - acc: 0.5455 - val_loss: 1.2956 - val_acc: 0.5387\n",
      "Epoch 37/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2693 - acc: 0.5453 - val_loss: 1.2983 - val_acc: 0.5420\n",
      "Epoch 38/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2651 - acc: 0.5483 - val_loss: 1.2774 - val_acc: 0.5470\n",
      "Epoch 39/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2662 - acc: 0.5484 - val_loss: 1.2761 - val_acc: 0.5476\n",
      "Epoch 40/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2599 - acc: 0.5489 - val_loss: 1.3072 - val_acc: 0.5408\n",
      "Epoch 41/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2521 - acc: 0.5535 - val_loss: 1.2705 - val_acc: 0.5474\n",
      "Epoch 42/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.2563 - acc: 0.5523 - val_loss: 1.3131 - val_acc: 0.5439\n",
      "Epoch 43/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2506 - acc: 0.5534 - val_loss: 1.2654 - val_acc: 0.5443\n",
      "Epoch 44/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2463 - acc: 0.5566 - val_loss: 1.2632 - val_acc: 0.5483\n",
      "Epoch 45/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2429 - acc: 0.5567 - val_loss: 1.2658 - val_acc: 0.5547\n",
      "Epoch 46/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2424 - acc: 0.5562 - val_loss: 1.2468 - val_acc: 0.5542\n",
      "Epoch 47/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2370 - acc: 0.5620 - val_loss: 1.2738 - val_acc: 0.5451\n",
      "Epoch 48/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 1.2331 - acc: 0.5607 - val_loss: 1.3588 - val_acc: 0.5253\n",
      "Epoch 49/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2335 - acc: 0.5599 - val_loss: 1.2757 - val_acc: 0.5472\n",
      "Epoch 50/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 1.2296 - acc: 0.5649 - val_loss: 1.2276 - val_acc: 0.5640\n"
     ]
    }
   ],
   "source": [
    "\n",
    "frozen_layers_config=[[\"conv1\",\"conv2\",\"fc1\"],\n",
    "                      [\"conv1\",\"conv2\",\"fc2\"],\n",
    "                      [\"conv1\",\"conv2\"], \n",
    "                      #[\"conv2\",\"fc1\",\"fc2\"], \n",
    "                      [\"fc1\",\"fc2\"]\n",
    "                      ,  ]\n",
    "retrained_models=[]\n",
    "\n",
    "for frozen_layers in frozen_layers_config:\n",
    "    print(\"Training model with frozen layers: %s\" % str(frozen_layers))\n",
    "    retrained_model = get_model(input_shape,num_classes,frozen_layers=frozen_layers)\n",
    "\n",
    "    retrained_model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    batch_size = 32\n",
    "    retrained_epochs = 50\n",
    "\n",
    "    weights_filename = 'rotation_test_model.hdf'\n",
    "    retrained_model.load_weights(weights_filename)\n",
    "\n",
    "    retrained_model.fit_generator(rotated_train_dataset,\n",
    "              steps_per_epoch=len(x_train) / batch_size,\n",
    "              epochs=retrained_epochs,\n",
    "              verbose=1,\n",
    "              validation_data=rotated_test_dataset)\n",
    "    retrained_models.append(retrained_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rotated_model_test_dataset score: loss=1.177862, accuracy=0.593800\n",
      "model_test_dataset score: loss=0.785554, accuracy=0.744400\n",
      "rotated_model_rotated_test_dataset score: loss=1.220749, accuracy=0.582000\n",
      "model_rotated_test_dataset score: loss=2.347124, accuracy=0.343800\n",
      "retrained_model_rotated_test_dataset_frozen=['conv1', 'conv2', 'fc1'] score: loss=1.614954, accuracy=0.436100\n",
      "retrained_model_test_dataset_frozen=['conv1', 'conv2', 'fc1'] score: loss=1.019024, accuracy=0.676700\n",
      "retrained_model_rotated_test_dataset_frozen=['conv1', 'conv2', 'fc2'] score: loss=1.381952, accuracy=0.543600\n",
      "retrained_model_test_dataset_frozen=['conv1', 'conv2', 'fc2'] score: loss=1.167411, accuracy=0.619300\n",
      "retrained_model_rotated_test_dataset_frozen=['conv1', 'conv2'] score: loss=1.285254, accuracy=0.568100\n",
      "retrained_model_test_dataset_frozen=['conv1', 'conv2'] score: loss=1.110265, accuracy=0.628500\n",
      "retrained_model_rotated_test_dataset_frozen=['conv2', 'fc1', 'fc2'] score: loss=1.704702, accuracy=0.391000\n",
      "retrained_model_test_dataset_frozen=['conv2', 'fc1', 'fc2'] score: loss=1.097757, accuracy=0.637600\n",
      "retrained_model_rotated_test_dataset_frozen=['fc1', 'fc2'] score: loss=1.418451, accuracy=0.499500\n",
      "retrained_model_test_dataset_frozen=['fc1', 'fc2'] score: loss=1.117678, accuracy=0.627100\n",
      "model_test_dataset report:              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.71      0.76      1000\n",
      "          1       0.83      0.88      0.86      1000\n",
      "          2       0.63      0.62      0.62      1000\n",
      "          3       0.60      0.52      0.56      1000\n",
      "          4       0.64      0.80      0.71      1000\n",
      "          5       0.70      0.61      0.65      1000\n",
      "          6       0.79      0.83      0.81      1000\n",
      "          7       0.79      0.80      0.80      1000\n",
      "          8       0.80      0.87      0.84      1000\n",
      "          9       0.84      0.80      0.82      1000\n",
      "\n",
      "avg / total       0.74      0.74      0.74     10000\n",
      "\n",
      "rotated_model_test_dataset report:              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.67      0.64      1000\n",
      "          1       0.72      0.66      0.69      1000\n",
      "          2       0.43      0.42      0.43      1000\n",
      "          3       0.48      0.35      0.41      1000\n",
      "          4       0.57      0.55      0.56      1000\n",
      "          5       0.54      0.56      0.55      1000\n",
      "          6       0.68      0.72      0.70      1000\n",
      "          7       0.54      0.70      0.61      1000\n",
      "          8       0.71      0.65      0.68      1000\n",
      "          9       0.65      0.65      0.65      1000\n",
      "\n",
      "avg / total       0.59      0.59      0.59     10000\n",
      "\n",
      "retrained_model_test_dataset_frozen=['conv1', 'conv2', 'fc1'] report:              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.72      0.72      1000\n",
      "          1       0.70      0.88      0.78      1000\n",
      "          2       0.66      0.42      0.51      1000\n",
      "          3       0.62      0.34      0.44      1000\n",
      "          4       0.65      0.67      0.66      1000\n",
      "          5       0.56      0.69      0.62      1000\n",
      "          6       0.81      0.72      0.77      1000\n",
      "          7       0.65      0.74      0.69      1000\n",
      "          8       0.72      0.83      0.77      1000\n",
      "          9       0.68      0.74      0.71      1000\n",
      "\n",
      "avg / total       0.68      0.68      0.67     10000\n",
      "\n",
      "retrained_model_test_dataset_frozen=['conv1', 'conv2', 'fc2'] report:              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.68      0.65      1000\n",
      "          1       0.72      0.80      0.76      1000\n",
      "          2       0.51      0.36      0.42      1000\n",
      "          3       0.40      0.50      0.44      1000\n",
      "          4       0.59      0.53      0.55      1000\n",
      "          5       0.57      0.56      0.57      1000\n",
      "          6       0.74      0.69      0.71      1000\n",
      "          7       0.64      0.65      0.64      1000\n",
      "          8       0.67      0.79      0.72      1000\n",
      "          9       0.75      0.66      0.70      1000\n",
      "\n",
      "avg / total       0.62      0.62      0.62     10000\n",
      "\n",
      "retrained_model_test_dataset_frozen=['conv1', 'conv2'] report:              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.68      0.66      1000\n",
      "          1       0.74      0.78      0.76      1000\n",
      "          2       0.50      0.37      0.43      1000\n",
      "          3       0.44      0.42      0.43      1000\n",
      "          4       0.56      0.62      0.59      1000\n",
      "          5       0.52      0.62      0.57      1000\n",
      "          6       0.72      0.73      0.72      1000\n",
      "          7       0.66      0.67      0.66      1000\n",
      "          8       0.72      0.72      0.72      1000\n",
      "          9       0.77      0.70      0.73      1000\n",
      "\n",
      "avg / total       0.63      0.63      0.63     10000\n",
      "\n",
      "retrained_model_test_dataset_frozen=['conv2', 'fc1', 'fc2'] report:              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.55      0.62      1000\n",
      "          1       0.72      0.81      0.76      1000\n",
      "          2       0.62      0.45      0.52      1000\n",
      "          3       0.46      0.49      0.47      1000\n",
      "          4       0.54      0.69      0.60      1000\n",
      "          5       0.61      0.48      0.54      1000\n",
      "          6       0.86      0.60      0.70      1000\n",
      "          7       0.66      0.74      0.70      1000\n",
      "          8       0.61      0.82      0.70      1000\n",
      "          9       0.69      0.74      0.71      1000\n",
      "\n",
      "avg / total       0.65      0.64      0.63     10000\n",
      "\n",
      "retrained_model_test_dataset_frozen=['fc1', 'fc2'] report:              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.60      0.66      1000\n",
      "          1       0.67      0.76      0.71      1000\n",
      "          2       0.63      0.42      0.51      1000\n",
      "          3       0.47      0.44      0.46      1000\n",
      "          4       0.61      0.59      0.60      1000\n",
      "          5       0.57      0.58      0.58      1000\n",
      "          6       0.74      0.69      0.71      1000\n",
      "          7       0.62      0.69      0.65      1000\n",
      "          8       0.68      0.74      0.71      1000\n",
      "          9       0.58      0.75      0.65      1000\n",
      "\n",
      "avg / total       0.63      0.63      0.62     10000\n",
      "\n",
      "model_test_dataset conf:\n",
      " [[713  21  74  15  27   4  12   9  97  28]\n",
      " [ 12 883   1   8   4   2   9   3  16  62]\n",
      " [ 40   4 616  46 128  44  61  36  16   9]\n",
      " [ 12  16  92 519  89 136  68  36  20  12]\n",
      " [ 11   1  42  41 798  13  28  48  16   2]\n",
      " [  8   4  59 162  68 613  21  51   9   5]\n",
      " [  9   2  44  31  55  16 830   4   6   3]\n",
      " [ 10   3  37  28  61  41   6 804   4   6]\n",
      " [ 32  38  10   3   7   2   6   3 872  27]\n",
      " [ 31  86  10   8  10   4   4  23  28 796]]\n",
      "rotated_model_test_dataset conf:\n",
      " [[667  25  78  13   8  14   0  37 116  42]\n",
      " [ 39 659  26  25   1  16  10  26  26 172]\n",
      " [120  13 425  53 147  66  63  83  21   9]\n",
      " [ 17  12  99 352  70 206 115  98  11  20]\n",
      " [ 24   1 131  32 552  22  74 146  12   6]\n",
      " [ 16  10  68 116  60 564  25 103  20  18]\n",
      " [  1   9  60  63  66  33 722  29   5  12]\n",
      " [ 24  13  42  30  64  80  17 697   9  24]\n",
      " [130  50  46  23   4  23  12  20 646  46]\n",
      " [ 43 128  20  29   2  17  17  49  41 654]]\n",
      "retrained_model_test_dataset_frozen=['conv1', 'conv2', 'fc1'] conf:\n",
      " [[724  42  29  13  13   9   4  20 104  42]\n",
      " [ 19 879   5   5   0   1   5   1  11  74]\n",
      " [113  39 418  25 140  82  44  57  57  25]\n",
      " [ 14  21  51 338  65 295  56  69  40  51]\n",
      " [ 32   3  41  29 671  22  44 123  24  11]\n",
      " [ 19  27  29  64  42 695   9  71  25  19]\n",
      " [  4  11  34  39  55  42 725  27  16  47]\n",
      " [ 23  20  14  21  39  81   5 739  18  40]\n",
      " [ 45  48  11   6   2   7   0   6 834  41]\n",
      " [ 19 167   6   8   0   2   2  17  35 744]]\n",
      "retrained_model_test_dataset_frozen=['conv1', 'conv2', 'fc2'] conf:\n",
      " [[677  25  53  32   5  19   1  23 128  37]\n",
      " [ 33 799  14  27   0   9   4   6  46  62]\n",
      " [118  22 357 129 150  78  60  45  36   5]\n",
      " [ 25  22  55 497  54 171  70  65  24  17]\n",
      " [ 49   6  95  93 525  22  70 100  30  10]\n",
      " [ 31  21  40 193  47 560  17  57  24  10]\n",
      " [  3  13  41 107  61  20 688  42  11  14]\n",
      " [ 47  10  20  87  46  77  10 645  19  39]\n",
      " [ 70  44  13  37   2  13   3   7 786  25]\n",
      " [ 42 142  10  35   4   9   9  24  66 659]]\n",
      "retrained_model_test_dataset_frozen=['conv1', 'conv2'] conf:\n",
      " [[676  28  54  33  13  19   3  19 118  37]\n",
      " [ 34 777  19  23   0  19   7  10  23  88]\n",
      " [111  20 369  93 194  73  60  44  31   5]\n",
      " [ 20  13  60 418  64 247  85  52  21  20]\n",
      " [ 28   2  76  45 617  25  77 107  20   3]\n",
      " [ 22  18  52 127  58 616  21  59  22   5]\n",
      " [  1  10  38  76  69  43 728  22   7   6]\n",
      " [ 38   5  28  62  69  96  13 666   9  14]\n",
      " [ 81  52  27  34   7  30   6   8 719  36]\n",
      " [ 39 120  10  48   3  11  10  27  33 699]]\n",
      "retrained_model_test_dataset_frozen=['conv2', 'fc1', 'fc2'] conf:\n",
      " [[551  38  48  24  38   6   3  27 213  52]\n",
      " [ 18 813   5   9  10   1   1   9  38  96]\n",
      " [ 77  19 452  89 175  35  32  61  40  20]\n",
      " [ 16  29  48 487  79 150  28  62  64  37]\n",
      " [ 16   4  37  57 695  28  16  91  44  12]\n",
      " [ 17  25  51 200  78 478   5  76  49  21]\n",
      " [ 10  19  49 104 130  42 596  21  16  13]\n",
      " [ 14  10  18  43  68  38   4 739  20  46]\n",
      " [ 28  46  18  25  13   3   3   3 823  38]\n",
      " [ 21 123   8  14  12   3   6  23  48 742]]\n",
      "retrained_model_test_dataset_frozen=['fc1', 'fc2'] conf:\n",
      " [[601  39  38  24  22  14   5  34 150  73]\n",
      " [ 15 759   4  13   0   6   1   5  24 173]\n",
      " [ 79  28 425  77 122  66  69  63  41  30]\n",
      " [ 14  34  37 442  55 186  68  65  29  70]\n",
      " [ 16  10  54  54 594  35  63 132  30  12]\n",
      " [  8  25  37 133  43 580  10  88  23  53]\n",
      " [  2  20  36  87  75  35 685  24   8  28]\n",
      " [ 19  16  20  53  46  70   9 692  15  60]\n",
      " [ 59  59  16  38   7  15   6   5 744  51]\n",
      " [ 20 146   4  19   6   3   6  15  32 749]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "Y_test=np.argmax(y_test, axis=1)\n",
    "reports={}\n",
    "scores={}\n",
    "confusion_matrices={}\n",
    "\n",
    "scores[\"rotated_model_test_dataset\"] = rotated_model.evaluate_generator(test_dataset)\n",
    "scores[\"model_test_dataset\"] = model.evaluate_generator(test_dataset)\n",
    "\n",
    "\n",
    "y_pred=model.predict(x_test)\n",
    "Y_pred = np.argmax(y_pred, axis=1)\n",
    "reports[\"model_test_dataset\"]=classification_report(Y_test, Y_pred)\n",
    "confusion_matrices[\"model_test_dataset\"]=confusion_matrix(Y_test, Y_pred)\n",
    "\n",
    "y_pred=rotated_model.predict(x_test)\n",
    "Y_pred = np.argmax(y_pred, axis=1)\n",
    "reports[\"rotated_model_test_dataset\"]=classification_report(Y_test, Y_pred)\n",
    "confusion_matrices[\"rotated_model_test_dataset\"]=confusion_matrix(Y_test, Y_pred)\n",
    "\n",
    "\n",
    "scores[\"rotated_model_rotated_test_dataset\"] = rotated_model.evaluate_generator(rotated_test_dataset)\n",
    "scores[\"model_rotated_test_dataset\"] = model.evaluate_generator(rotated_test_dataset)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i,retrained_model in enumerate(retrained_models):\n",
    "    config=frozen_layers_config[i]\n",
    "    key=\"retrained_model_test_dataset_frozen=%s\" % config\n",
    "    rotated_key=\"retrained_model_rotated_test_dataset_frozen=%s\" % config\n",
    "    scores[rotated_key] = retrained_model.evaluate_generator(rotated_test_dataset)\n",
    "    scores[key] = retrained_model.evaluate_generator(test_dataset)\n",
    "    y_pred=retrained_model.predict(x_test)\n",
    "    Y_pred = np.argmax(y_pred, axis=1)\n",
    "    reports[key]=classification_report(Y_test, Y_pred)\n",
    "    confusion_matrices[key]=confusion_matrix(Y_test, Y_pred)\n",
    "\n",
    "for k,v in scores.items():\n",
    "    print('%s score: loss=%f, accuracy=%f' % (k,v[0],v[1]))\n",
    "\n",
    "\n",
    "\n",
    "for k,v in reports.items():\n",
    "    print('%s report: %s' % (k,v))\n",
    "    \n",
    "    \n",
    "for k,v in confusion_matrices.items():\n",
    "    print('%s conf:\\n %s' % (k,v))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
