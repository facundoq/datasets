{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.datasets import cifar10\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import resnext\n",
    "import modelresnext\n",
    "print(dir(modelresnext))\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "nb_classes = 10\n",
    "nb_epoch = 100\n",
    "\n",
    "img_rows, img_cols = 32, 32\n",
    "img_channels = 3\n",
    "\n",
    "img_dim = (img_channels, img_rows, img_cols) if K.image_dim_ordering() == \"th\" else (img_rows, img_cols, img_channels)\n",
    "depth = 29\n",
    "cardinality = 8\n",
    "width = 16\n",
    "\n",
    "model = \"mine\" # \"other\"\n",
    "if model== \"mine\":\n",
    "    weights_file = \"weights/mine.h5\"\n",
    "    model= resnext.residual_network(img_dim,nb_classes,cardinality,width)\n",
    "else:\n",
    "    weights_file = \"weights/other.h5\"\n",
    "    model = modelresnext.fuckshit(img_dim, depth=depth, cardinality=cardinality, width=width, weights=None, classes=nb_classes)\n",
    "\n",
    "print(\"Model created\")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "optimizer = Adam(lr=1e-3)  # Using Adam instead of SGD to speed up training\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "print(\"Finished compiling\")\n",
    "print(\"Building model...\")\n",
    "\n",
    "(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
    "\n",
    "trainX = trainX.astype('float32')\n",
    "testX = testX.astype('float32')\n",
    "\n",
    "trainX /= 255.\n",
    "testX /= 255.\n",
    "\n",
    "Y_train = np_utils.to_categorical(trainY, nb_classes)\n",
    "Y_test = np_utils.to_categorical(testY, nb_classes)\n",
    "\n",
    "generator = ImageDataGenerator(rotation_range=15,\n",
    "                               width_shift_range=5./32,\n",
    "                               height_shift_range=5./32,\n",
    "                               horizontal_flip=True)\n",
    "\n",
    "generator.fit(trainX, seed=0)\n",
    "\n",
    "out_dir = \"weights/\"\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "# Load model\n",
    "\n",
    "\n",
    "if False and os.path.exists(weights_file):\n",
    "    model.load_weights(weights_file)\n",
    "    print(\"Model loaded.\")\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=np.sqrt(0.1),\n",
    "                               cooldown=0, patience=10, min_lr=1e-6)\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(weights_file, monitor=\"val_acc\", save_best_only=True,\n",
    "                                   save_weights_only=True, mode='auto')\n",
    "\n",
    "callbacks = [lr_reducer, model_checkpoint]\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 1/100\n",
      "390/390 [==============================] - 237s 609ms/step - loss: 1.9653 - acc: 0.2718 - val_loss: 1.6992 - val_acc: 0.3815\n",
      "Epoch 2/100\n",
      "390/390 [==============================] - 235s 603ms/step - loss: 1.6807 - acc: 0.3789 - val_loss: 1.4729 - val_acc: 0.4636\n",
      "Epoch 3/100\n",
      "390/390 [==============================] - 235s 604ms/step - loss: 1.5523 - acc: 0.4317 - val_loss: 1.4179 - val_acc: 0.4762\n",
      "Epoch 4/100\n",
      "390/390 [==============================] - 236s 604ms/step - loss: 1.4801 - acc: 0.4585 - val_loss: 1.3368 - val_acc: 0.5072\n",
      "Epoch 5/100\n",
      "390/390 [==============================] - 235s 604ms/step - loss: 1.4296 - acc: 0.4789 - val_loss: 1.2762 - val_acc: 0.5346\n",
      "Epoch 6/100\n",
      "390/390 [==============================] - 236s 604ms/step - loss: 1.3796 - acc: 0.4973 - val_loss: 1.2366 - val_acc: 0.5501\n",
      "Epoch 7/100\n",
      "390/390 [==============================] - 235s 603ms/step - loss: 1.3475 - acc: 0.5122 - val_loss: 1.2271 - val_acc: 0.5553\n",
      "Epoch 8/100\n",
      "390/390 [==============================] - 235s 603ms/step - loss: 1.3137 - acc: 0.5242 - val_loss: 1.1602 - val_acc: 0.5777\n",
      "Epoch 9/100\n",
      "390/390 [==============================] - 236s 604ms/step - loss: 1.2821 - acc: 0.5337 - val_loss: 1.1636 - val_acc: 0.5805\n",
      "Epoch 10/100\n",
      "390/390 [==============================] - 235s 603ms/step - loss: 1.2666 - acc: 0.5388 - val_loss: 1.1356 - val_acc: 0.5900\n",
      "Epoch 11/100\n",
      "390/390 [==============================] - 235s 603ms/step - loss: 1.2476 - acc: 0.5507 - val_loss: 1.1288 - val_acc: 0.5911\n",
      "Epoch 12/100\n",
      "390/390 [==============================] - 235s 603ms/step - loss: 1.2307 - acc: 0.5540 - val_loss: 1.0918 - val_acc: 0.6057\n",
      "Epoch 13/100\n",
      "390/390 [==============================] - 235s 603ms/step - loss: 1.2163 - acc: 0.5644 - val_loss: 1.0795 - val_acc: 0.6078\n",
      "Epoch 14/100\n",
      "390/390 [==============================] - 235s 603ms/step - loss: 1.2055 - acc: 0.5628 - val_loss: 1.1414 - val_acc: 0.5899\n",
      "Epoch 15/100\n",
      "390/390 [==============================] - 235s 603ms/step - loss: 1.1839 - acc: 0.5721 - val_loss: 1.0986 - val_acc: 0.6082\n",
      "Epoch 16/100\n",
      "390/390 [==============================] - 235s 603ms/step - loss: 1.1803 - acc: 0.5753 - val_loss: 1.0561 - val_acc: 0.6173\n",
      "Epoch 17/100\n",
      "390/390 [==============================] - 235s 603ms/step - loss: 1.1623 - acc: 0.5818 - val_loss: 1.0482 - val_acc: 0.6226\n",
      "Epoch 18/100\n",
      "390/390 [==============================] - 235s 604ms/step - loss: 1.1531 - acc: 0.5847 - val_loss: 1.0526 - val_acc: 0.6198\n",
      "Epoch 19/100\n",
      "390/390 [==============================] - 235s 603ms/step - loss: 1.1535 - acc: 0.5850 - val_loss: 1.0190 - val_acc: 0.6326\n",
      "Epoch 20/100\n",
      "154/390 [==========>...................] - ETA: 2:21 - loss: 1.1409 - acc: 0.5903"
     ]
    }
   ],
   "source": [
    "print(\"Training...\")\n",
    "model.fit_generator(generator.flow(trainX, Y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=len(trainX) // batch_size,\n",
    "                    epochs=nb_epoch,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=(testX, Y_test),\n",
    "                    validation_steps=testX.shape[0] // batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "yPreds = model.predict(testX)\n",
    "yPred = np.argmax(yPreds, axis=1)\n",
    "yTrue = testY\n",
    "\n",
    "accuracy = metrics.accuracy_score(yTrue, yPred) * 100\n",
    "error = 100 - accuracy\n",
    "print(\"Accuracy : \", accuracy)\n",
    "print(\"Error : \", error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
